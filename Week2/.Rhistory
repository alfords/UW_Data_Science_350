install.packages("plyr")
install.packages("ggplot2")
g = rnorm(10,5)
plot(g)
pwd()
getwd()
install.packages("UsingR")
ls -l
exit()
install.packages(c("boot", "class", "cluster", "codetools", "colorspace", "evaluate", "foreign", "formatR", "Formula", "ggplot2", "highr", "Hmisc", "jsonlite", "KernSmooth", "knitr", "lattice", "manipulate", "markdown", "MASS", "Matrix", "mgcv", "mime", "nlme", "nnet", "plyr", "Rcpp", "RCurl", "rpart", "spatial", "stringr", "survival"))
library(data.table)
library(logging)
library(RSQLite)
install.packages("data.table", "logging", "RSQLite")
install.packages("data.table")
install.packages('logging')
install.packages(RSQLite)
install.packages("RSQLite")
library(data.table)
library(logging)
library(RSQLite)
list.dirs
A_matrix = matrix(4, nrow=4, ncol=3) # Makes use of broadcasting
View(A_matrix)
B_matrix = matrix(1:50, nrow=4, ncol=3)
View(B_matrix)
A_matrix + B_matrix
A_matrix * B_matrix
A_matrix %*% B_matrix
A_matrix %*% t(B_matrix)
x_values = seq(from=as.Date('2015-01-01'),
to=as.Date('2015-02-12'),
by = 3)
df = data.frame('dates' = x_values,
'x1'    = runif(15,-10,20),
'x2'    = 1:15,
'x3'    = strsplit('MississippiMath','')[[1]])
View(df)
df$x3 = as.character(df$x3)
df$x3 = tolower(df$x3)
View(df)
str(df)
head(df)
tail(df, n=10)
df = as.data.table(df)
View(df)
df[,sum(x1)]
df[,c(sum(x1),sd(x2))]
?logging
x_values
install.packages("XML")
nfl_site = "http://www.usatoday.com/sports/nfl/arrests/"
nfl_html = readHTMLTable(nfl_site)
nfl_site = "http://www.usatoday.com/sports/nfl/arrests/"
library(XML)
nfl_html = readHTMLTable(nfl_site)
nfl_html = readHTMLTable(nfl_site)
nfl_html
nfl_data = nfl_html[[1]]
nfl_html
db_file = 'test_db.db'
conn = dbConnect(dbDriver("SQLite"), dbname=db_file)
dbWriteTable(conn, 'table_name', medals_data, overwrite=TRUE)
medals_data <- read.table("medals.txt", sep="\t", header=TRUE)
p = 0.75
n = 1000
?rbinom
bern_samples = rbinom(n, 1, p)
bern_sample_mean = sum(bern_samples)/length(bern_samples)
bern_sample_var = bern_sample_mean * (1-bern_sample_mean)
##--------------------------------------------
##
## Exploring Data in R (lecture 1)
##
## Class: PCE Data Science Methods Class
##
## Contains examples of:
##
## -Working with Distributions
##
## -Visually/Numerically Exploring data
##
##--------------------------------------------
##-----Exploring data Visually----
# Bernoulli (Binomial with n = 1)
p = 0.75
n = 1000
bern_samples = rbinom(n, 1, p)
bern_sample_mean = sum(bern_samples)/length(bern_samples)
bern_sample_var = bern_sample_mean * (1-bern_sample_mean)
bern_var = p*(1-p)
# Binomial
N = c(5, 25, 75)
binom_samples = lapply(N, function(x) rbinom(n, x, p))
binom_sample_means = lapply(binom_samples, mean)
binom_means = N*p
binom_sample_vars = lapply(binom_samples, var)
binom_vars = N*p*(1-p)
par(mfrow=c(2,2))
for (i in 1:3){
hist(binom_samples[[i]], main=paste(N[i],'Experiments'), freq=FALSE)
x_norm = seq(0,N[i], by = 0.025)
y_norm = dnorm(x_norm, mean=binom_means[i], sd=sqrt(binom_vars[i]))
lines(x_norm, y_norm)
}
setwd("/Users/voitel/TRAINING/UW_Data_Science/UW_Data_Science_350/Week2")
##--------------------------------------------
##
## R Review Homework
##
## Aleksey Kramer
##
## Homework 2 R-script
##
##--------------------------------------------
##-----Set working directory-----
setwd("C:\\Users\\Aleksey\\Documents\\School\\UW_Data_Science\\UW_Data_Science_350\\Week2")
##-----Load Libraries-----
library(dplyr)
library(data.table)
source('weather_retrieval.R')
# Load jittered Data
headcount = read.csv('JitteredHeadCount.csv', stringsAsFactors = FALSE)
headcount$DateFormat = as.Date(headcount$DateFormat, format="%m/%d/%Y")
weather_file_name = 'las_vegas_hourly_weather.csv'
# Let's test if the file is in the directry using list.files()
#        If it is, load that file instead of running webscraper
# <<INSERT CODE HERE>>>
# <<CHANGE BELOW CODE BASE ON ABOVE CODE>>>
# If it isn't, run webscraper:
# Look at dates:
if (file.exists(weather_file_name)) {
weather_data = read.csv(weather_file_name, stringsAsFactors = FALSE)
names(weather_data) = c('time','temp','dew_pt','humidity','pressure',
'visibility','wind_dir','wind_speed','gust_speed',
'precipitation','events','conditions',
'wind_dir_deg','date')
weather_data$date = as.Date(weather_data$date)
} else {
range(headcount$DateFormat)
airport = 'KLAS'
dates = seq(from=min(headcount$DateFormat), to=max(headcount$DateFormat), by=1)
weather_data = get_weather_data(airport, dates)
names(weather_data) = c('time','temp','dew_pt','humidity','pressure',
'visibility','wind_dir','wind_speed','gust_speed',
'precipitation','events','conditions',
'wind_dir_deg','date')
write.csv(weather_data, file = weather_file_name, row.names=FALSE)
}
# Let's create a datetime in the weather data
weather_data$datetime = paste(weather_data$date,weather_data$time)
weather_data$datetime = strptime(weather_data$datetime, format="%Y-%m-%d %I:%M %p")
weather_data$Hour = as.numeric(format(round(weather_data$datetime, units="hours"), format="%H"))
# Let's merge with different methods.
#   - If we were truly merging to analyze casino data, we don't want to lose
#      headcount data if weather doesn't exist, so we want to do a
#      left merge (keeping all the headcount data)
#
#   - Remember, we want to merge on date AND hour.
#   - Note: the headcount data has multiple rows for these (more than 1 game type)
# Check for duplicates!
anyDuplicated(headcount[c("DateFormat", "Hour","GameCode")])
anyDuplicated(weather_data[c("date", 'Hour')]) # Oh no!  How could this happen?
# Drop for now:
weather_data = weather_data[!duplicated(weather_data[c("date", 'Hour')]),]
# Rename some columns:
intersect(names(headcount), names(weather_data))
weather_data$DateFormat = weather_data$date
weather_data$date = NULL
# Pick one of the below merges, and comment out the other two.
# <<<CHANGE BELOW MERGING CODE>>>
# Merge (base)
## headcount_base_all = merge(headcount, weather_data, all.x=TRUE, by=c("DateFormat","Hour"))
# Merge(data.table)
# Note that data.table has a problem.  It canNOT take POSIX values. So we drop it (we are
#      done with that column anyways)
weather_data$datetime = NULL
library(data.table)
headcount = as.data.table(headcount)
weather_data = as.data.table(weather_data)
# Set keys for faster merges
setkeyv(headcount, c("DateFormat", "Hour"))
setkeyv(weather_data, c("DateFormat", "Hour"))
headcount_dt_all = merge(headcount, weather_data, all.x=TRUE, by=c("DateFormat", "Hour"))
# Merge(dplyr)
## library(dplyr)
## headcount_dplyr_all = left_join(headcount, weather_data, by=c("DateFormat", "Hour"))
##----Find another insight involving weather------
# For now, drop all NA rows:
#     use the command 'complete.cases'
# Use 'complete.cases()' as a row filter on your data frame.
# <<<INSERT NEW CODE HERE>>>
# Isolating complete cases
good <- complete.cases(headcount_dt_all)
headcount_dt_all <- headcount_dt_all[good,]
# Setting weather condition as factor variable
headcount_dt_all$conditions <- as.factor(headcount_dt_all$conditions)
# Plot weather conditions vs. Table Occupancy
plot(headcount_dt_all$conditions, headcount_dt_all$TablesOcc)
print("When the conditions are 'Rain' or 'Widespread Dust', table occupancy increases")
# isolating dust and rain conditions/table occupancies
dust_occ <- headcount_dt_all[headcount_dt_all$conditions == 'Widespread Dust',]$TablesOcc
rain_occ <- headcount_dt_all[headcount_dt_all$conditions == 'Rain',]$TablesOcc
# removing dust and rain conditions from the test data frame
temp <- headcount_dt_all
temp <- temp[conditions != 'Widespread Dust',]
temp <- temp[conditions != 'Rain',]
# Calculating means for days when conditions are Rain and Widespread Dust
dust_mean <- mean(dust_occ)
rain_mean <- mean(rain_occ)
# Calculating mean for all conditions except for Rain and Widespread Dust
all_mean <- mean(temp$TablesOcc)
# Calculating difference in means for Widespread Dust vs all other conditions
1 - all_mean / dust_mean
# Calculating difference in means for Rain vs all other conditions
1 - all_mean / rain_mean
# The differnce in means between table occupancy during the days when weather condition is Widespread Dust
# vs. all other weather conditions is 27%, meaning that table occupancy increases in average by 27%
# when the weather condition is Widespread Dust
# The differnce in means between table occupancy during the days when weather condition is Rain
# vs. all other weather conditions is 35%, meaning that table occupancy increases in average by 35%
# when the weather condition is Rain
setwd("C:\\Users\\Aleksey\\Documents\\School\\UW_Data_Science\\UW_Data_Science_350\\Week2")
##--------------------------------------------
##
## R Review Homework
##
## Aleksey Kramer
##
## Homework 2 R-script
##
##--------------------------------------------
##-----Set working directory-----
setwd("C:\\Users\\Aleksey\\Documents\\School\\UW_Data_Science\\UW_Data_Science_350\\Week2")
##-----Load Libraries-----
library(dplyr)
library(data.table)
source('weather_retrieval.R')
# Load jittered Data
headcount = read.csv('JitteredHeadCount.csv', stringsAsFactors = FALSE)
headcount$DateFormat = as.Date(headcount$DateFormat, format="%m/%d/%Y")
weather_file_name = 'las_vegas_hourly_weather.csv'
# Let's test if the file is in the directry using list.files()
#        If it is, load that file instead of running webscraper
# <<INSERT CODE HERE>>>
# <<CHANGE BELOW CODE BASE ON ABOVE CODE>>>
# If it isn't, run webscraper:
# Look at dates:
if (file.exists(weather_file_name)) {
weather_data = read.csv(weather_file_name, stringsAsFactors = FALSE)
names(weather_data) = c('time','temp','dew_pt','humidity','pressure',
'visibility','wind_dir','wind_speed','gust_speed',
'precipitation','events','conditions',
'wind_dir_deg','date')
weather_data$date = as.Date(weather_data$date)
} else {
range(headcount$DateFormat)
airport = 'KLAS'
dates = seq(from=min(headcount$DateFormat), to=max(headcount$DateFormat), by=1)
weather_data = get_weather_data(airport, dates)
names(weather_data) = c('time','temp','dew_pt','humidity','pressure',
'visibility','wind_dir','wind_speed','gust_speed',
'precipitation','events','conditions',
'wind_dir_deg','date')
write.csv(weather_data, file = weather_file_name, row.names=FALSE)
}
# Let's create a datetime in the weather data
weather_data$datetime = paste(weather_data$date,weather_data$time)
weather_data$datetime = strptime(weather_data$datetime, format="%Y-%m-%d %I:%M %p")
weather_data$Hour = as.numeric(format(round(weather_data$datetime, units="hours"), format="%H"))
# Let's merge with different methods.
#   - If we were truly merging to analyze casino data, we don't want to lose
#      headcount data if weather doesn't exist, so we want to do a
#      left merge (keeping all the headcount data)
#
#   - Remember, we want to merge on date AND hour.
#   - Note: the headcount data has multiple rows for these (more than 1 game type)
# Check for duplicates!
anyDuplicated(headcount[c("DateFormat", "Hour","GameCode")])
anyDuplicated(weather_data[c("date", 'Hour')]) # Oh no!  How could this happen?
# Drop for now:
weather_data = weather_data[!duplicated(weather_data[c("date", 'Hour')]),]
# Rename some columns:
intersect(names(headcount), names(weather_data))
weather_data$DateFormat = weather_data$date
weather_data$date = NULL
# Pick one of the below merges, and comment out the other two.
# <<<CHANGE BELOW MERGING CODE>>>
# Merge (base)
## headcount_base_all = merge(headcount, weather_data, all.x=TRUE, by=c("DateFormat","Hour"))
# Merge(data.table)
# Note that data.table has a problem.  It canNOT take POSIX values. So we drop it (we are
#      done with that column anyways)
weather_data$datetime = NULL
library(data.table)
headcount = as.data.table(headcount)
weather_data = as.data.table(weather_data)
# Set keys for faster merges
setkeyv(headcount, c("DateFormat", "Hour"))
setkeyv(weather_data, c("DateFormat", "Hour"))
headcount_dt_all = merge(headcount, weather_data, all.x=TRUE, by=c("DateFormat", "Hour"))
# Merge(dplyr)
## library(dplyr)
## headcount_dplyr_all = left_join(headcount, weather_data, by=c("DateFormat", "Hour"))
##----Find another insight involving weather------
# For now, drop all NA rows:
#     use the command 'complete.cases'
# Use 'complete.cases()' as a row filter on your data frame.
# <<<INSERT NEW CODE HERE>>>
# Isolating complete cases
good <- complete.cases(headcount_dt_all)
headcount_dt_all <- headcount_dt_all[good,]
# Setting weather condition as factor variable
headcount_dt_all$conditions <- as.factor(headcount_dt_all$conditions)
# Plot weather conditions vs. Table Occupancy
plot(headcount_dt_all$conditions, headcount_dt_all$TablesOcc)
print("When the conditions are 'Rain' or 'Widespread Dust', table occupancy increases")
# isolating dust and rain conditions/table occupancies
dust_occ <- headcount_dt_all[headcount_dt_all$conditions == 'Widespread Dust',]$TablesOcc
rain_occ <- headcount_dt_all[headcount_dt_all$conditions == 'Rain',]$TablesOcc
# removing dust and rain conditions from the test data frame
temp <- headcount_dt_all
temp <- temp[conditions != 'Widespread Dust',]
temp <- temp[conditions != 'Rain',]
# Calculating means for days when conditions are Rain and Widespread Dust
dust_mean <- mean(dust_occ)
rain_mean <- mean(rain_occ)
# Calculating mean for all conditions except for Rain and Widespread Dust
all_mean <- mean(temp$TablesOcc)
# Calculating difference in means for Widespread Dust vs all other conditions
1 - all_mean / dust_mean
# Calculating difference in means for Rain vs all other conditions
1 - all_mean / rain_mean
# The differnce in means between table occupancy during the days when weather condition is Widespread Dust
# vs. all other weather conditions is 27%, meaning that table occupancy increases in average by 27%
# when the weather condition is Widespread Dust
# The differnce in means between table occupancy during the days when weather condition is Rain
# vs. all other weather conditions is 35%, meaning that table occupancy increases in average by 35%
# when the weather condition is Rain
